# Look at feature selection for random forest

Identify which features give the most information when making decision tree.
Gini-index info theory measure for differences in datasets with respect to rows. 

Identify feature selection tool to pick
Look for other information theory type measures for dataset similarities 

Look at permutation between euclidian differences when removing a single feature versus other.  

Do a false discovery post hoc correction to avoid false positives. Benjamini Hocberger. 

sk.learn multi class vs all vs the rest.

Information gain test to classify. 

Rank based on information gain: bits is the measure of gain.

Identify feature selection methods. Lots exist. They will pick 15 most important features. 
